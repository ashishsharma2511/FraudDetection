# ğŸš¨ Real-Time Fraud Detection with PySpark, Kafka, and MLlib

A real-time fraud detection pipeline that ingests transaction data via Kafka, processes it with PySpark Structured Streaming, and classifies transactions using a machine learning model built with Spark MLlib.

---

## ğŸ“Œ Features

- ğŸ”„ Real-time data ingestion using Apache Kafka  
- âš™ï¸ Stream processing with PySpark Structured Streaming  
- ğŸ¤– Logistic Regression-based fraud prediction using Spark MLlib  
- ğŸ—ƒï¸ Offline model training pipeline  
- ğŸ“¦ Dockerized Kafka (Zookeeper + Kafka Broker)

---

## ğŸ§° Tech Stack

- Python 3  
- Apache Spark (PySpark)  
- Apache Kafka  
- Spark MLlib  
- Docker  
- WSL (Windows Subsystem for Linux) for compatibility

---

## ğŸ§  Model Overview

- **Model Type**: Logistic Regression  
- **Training Data**: Synthetic transaction dataset  
- **Features Used**: Transaction amount, transaction type, etc.  
- **Label**: Binary fraud classification (0 = legit, 1 = fraud)

---

## ğŸ—‚ï¸ Project Structure

```
fraud_project/
â”œâ”€â”€ data/                      # Training data (CSV)
â”œâ”€â”€ spark_job/
â”‚   â”œâ”€â”€ spark_stream.py        # Real-time stream processor
â”‚   â”œâ”€â”€ producer.py            # Kafka producer (pushes transactions)
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ train_model.py             # Offline model training script
â”œâ”€â”€ fraud_model/               # Saved MLlib model (Spark pipeline)
â”œâ”€â”€ docker-compose.yml         # Kafka + Zookeeper stack
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### 1. Clone the Repo

```bash
git clone https://github.com/yourusername/fraud_project.git
cd fraud_project
```

### 2. Start Kafka Services

```bash
docker-compose up -d
```

### 3. Train the Model

```bash
python3 train_model.py
```

### 4. Start the Kafka Producer

```bash
python3 spark_job/producer.py
```

### 5. Run the Streaming Job

```bash
python3 spark_job/spark_stream.py
```

---

## ğŸ§ª Sample Output

- Incoming transaction printed to console
- Model prediction: `FRAUD` or `LEGIT`

---

## ğŸ› ï¸ Troubleshooting

- **Permission errors on Windows?** Use WSL (recommended)
- **Spark Streaming can't find Kafka source?** Ensure you have the Kafka Spark package in `PYSPARK_SUBMIT_ARGS`

---

## ğŸ“ˆ Future Enhancements

- Model accuracy optimization with advanced features  
- Integration with alert systems (Slack, email)  
- Dashboard for monitoring stream output  

---

## ğŸ¤ Contributing

Pull requests welcome. For major changes, please open an issue first.

---

## ğŸ“„ License

MIT License
